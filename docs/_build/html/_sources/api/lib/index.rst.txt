Library Components
==================

Core library components and utilities supporting the TALENT models.

.. toctree::
   :maxdepth: 2
   :caption: Contents:

   amformer
   bishop
   danets
   dnnr
   excelformer
   hyperfast
   node
   num_embeddings
   periodic_tab_dl
   pfn_v2
   ptarl
   realmlp
   tabcaps
   tabicl
   tabm
   tabnet
   tabpfn
   tabptm
   tabr
   TData
   trompt

Overview
--------

The library components module provides specialized implementations and utilities for various deep learning models in TALENT. These components include attention mechanisms, feature transformers, model-specific optimizations, and data processing utilities.

Available Components
------------------

**Core Utilities:**
- TData: Optimized data structure for efficient tabular data handling
- num_embeddings: Advanced numerical feature embedding techniques

**Model-Specific Components:**
- TabNet: Interpretable deep learning for tabular data
- TabPFN: Prior-data fitted networks
- TabR: Tabular representation learning
- TabM: Tabular modeling with transformers
- RealMLP: Real-valued MLP for tabular data
- BiSHop: Bidirectional hierarchical attention
- NODE: Neural oblivious decision ensembles
- HyperFast: Fast hyperparameter optimization
- ExcelFormer: Transformer for tabular data
- DANets: Deep attention networks
- TabCaps: Capsule networks for tabular data
- TabICL: In-context learning for tabular data

**Specialized Components:**
- Periodic Tabular DL: Periodic embeddings for tabular data
- TROMPT: Tabular prompting mechanisms
- PTARL: Policy gradient methods for tabular RL
- AmFormer: Attention mechanisms for transformers
- TabPTM: Pre-trained models for tabular data
- DNNR: Deep nearest neighbor regression

Common Features
--------------

All library components in TALENT share the following features:

- PyTorch integration for deep learning models
- Efficient data processing and memory optimization
- Modular design for easy integration
- Support for both numerical and categorical features
- Configurable hyperparameters and architectures
- GPU acceleration support

Usage Example
------------

.. code-block:: python

    from TALENT.model.lib import TabNet, TData
    
    # Initialize data structure
    data = TData(X_train, y_train)
    
    # Initialize model component
    tabnet = TabNet(input_dim, output_dim)
    
    # Train the model
    tabnet.fit(data) 