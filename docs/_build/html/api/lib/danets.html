

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DANet &mdash; LAMDA-TALENT  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            LAMDA-TALENT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html">How to Use TALENT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#cloning-the-repository">1. Cloning the Repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#running-experiments">2. Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#adding-new-methods">3. Adding New Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#configuring-hyperparameters">4. Configuring Hyperparameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#troubleshooting">5. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Methods</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html">Methods in TALENT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html#deep-learning-methods">Deep Learning Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html#classical-methods">Classical Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html#methodology-summary">Methodology Summary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Dependencies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html">Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html#python-libraries">Python Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html#optional-dependencies">Optional Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html#additional-notes">Additional Notes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmark_Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html">Benchmark Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#available-datasets">Available Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#downloading-datasets">Downloading Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#dataset-structure">Dataset Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#placing-datasets">Placing Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#using-datasets">Using Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#custom-datasets">Custom Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#task-types">Task Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Experimental_Results</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../experimental_results.html">Experimental Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental_results.html#evaluation-metrics">Evaluation Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental_results.html#results-summary">Results Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental_results.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../core.html">Core Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning.html">Deep Learning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../classical_methods.html">Classical Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lib.html">Library Components</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Acknowledgements</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../acknowledgements.html">Acknowledgments</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">LAMDA-TALENT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><strong>DANet</strong></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api/lib/danets.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="danet">
<h1><strong>DANet</strong><a class="headerlink" href="#danet" title="Link to this heading"></a></h1>
<p>Tabular data are ubiquitous in real world applications. Although many commonly-used neural components (e.g., convolution) and extensible neural networks (e.g., ResNet) have been developed by the machine learning community, few of them were effective for tabular data and few designs were adequately tailored for tabular data structures. In this paper, we propose a novel and flexible neural component for tabular data, called Abstract Layer (AbstLay), which learns to explicitly group correlative input features and generate higher-level features for semantics abstraction. Also, we design a structure re-parameterization method to compress AbstLay, thus reducing the computational complexity by a clear margin in the reference phase. A special basic block is built using AbstLays, and we construct a family of Deep Abstract Networks (DANets) for tabular data classification and regression by stacking such blocks. In DANets, a special shortcut path is introduced to fetch information from raw tabular features, assisting feature interactions across different levels. Comprehensive experiments on real-world tabular datasets show that our AbstLay and DANets are effective for tabular data classification and regression, and the computational complexity is superior to competitive methods.</p>
<section id="class-acceleratedcreator-object">
<h2>class AcceleratedCreator(object)<a class="headerlink" href="#class-acceleratedcreator-object" title="Link to this heading"></a></h2>
<p>A creator class to accelerate neural network modules by processing and modifying layers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">base_out_dim</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input_dim</strong> <em>(int)</em> - Input dimension of the network.</p></li>
<li><p><strong>base_out_dim</strong> <em>(int)</em> - Base output dimension for the network layers.</p></li>
<li><p><strong>k</strong> <em>(int)</em> - Parameter used in the Extractor for weight computation.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">)</span>
</pre></div>
</div>
<p>Modifies the input network by processing its initial layer and each subsequent layer.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>network</strong> - The neural network to be accelerated.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p>Modified network with processed layers.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">extract_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">basicblock</span><span class="p">,</span> <span class="n">base_input_dim</span><span class="p">,</span> <span class="n">fix_input_dim</span><span class="p">)</span>
</pre></div>
</div>
<p>Extracts and processes individual modules (convolutional and downsample layers) within a basic block.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>basicblock</strong> - The basic block containing layers to process.</p></li>
<li><p><strong>base_input_dim</strong> <em>(int)</em> - Base input dimension for the block.</p></li>
<li><p><strong>fix_input_dim</strong> <em>(int)</em> - Fixed input dimension for downsampling layers.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p>Modified basic block with processed layers.</p></li>
</ul>
</section>
<section id="class-extractor-object">
<h2>class Extractor(object)<a class="headerlink" href="#class-extractor-object" title="Link to this heading"></a></h2>
<p>A class to extract parameters from abstract layers and compute compressed weights.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>k</strong> <em>(int)</em> - Parameter used for weight computation.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">get_parameter</span><span class="p">(</span><span class="n">abs_layer</span><span class="p">)</span>
</pre></div>
</div>
<p>Extracts necessary parameters from an abstract layer, including batch normalization stats and weights.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>abs_layer</strong> - The abstract layer to extract parameters from.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>alpha</strong> <em>(torch.Tensor)</em> - Batch normalization weight data.</p></li>
<li><p><strong>beta</strong> <em>(torch.Tensor)</em> - Batch normalization bias data.</p></li>
<li><p><strong>eps</strong> <em>(float)</em> - Batch normalization epsilon value.</p></li>
<li><p><strong>mu</strong> <em>(torch.Tensor)</em> - Running mean from batch normalization.</p></li>
<li><p><strong>var</strong> <em>(torch.Tensor)</em> - Running variance from batch normalization.</p></li>
<li><p><strong>sparse_weight</strong> <em>(torch.Tensor)</em> - Sparse weights from the masker.</p></li>
<li><p><strong>process_weight</strong> <em>(torch.Tensor)</em> - Weight data from the fully connected layer.</p></li>
<li><p><strong>process_bias</strong> <em>(torch.Tensor or None)</em> - Bias data from the fully connected layer (if exists).</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">compute_weights</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">sw</span><span class="p">,</span> <span class="n">pw</span><span class="p">,</span> <span class="n">pb</span><span class="p">,</span> <span class="n">base_input_dim</span><span class="p">,</span> <span class="n">base_output_dim</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p>Computes compressed weights and biases using extracted parameters.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>a</strong> <em>(torch.Tensor)</em> - Alpha (batch norm weight).</p></li>
<li><p><strong>b</strong> <em>(torch.Tensor)</em> - Beta (batch norm bias).</p></li>
<li><p><strong>eps</strong> <em>(float)</em> - Batch norm epsilon.</p></li>
<li><p><strong>mu</strong> <em>(torch.Tensor)</em> - Running mean.</p></li>
<li><p><strong>var</strong> <em>(torch.Tensor)</em> - Running variance.</p></li>
<li><p><strong>sw</strong> <em>(torch.Tensor)</em> - Sparse weight.</p></li>
<li><p><strong>pw</strong> <em>(torch.Tensor)</em> - Process weight.</p></li>
<li><p><strong>pb</strong> <em>(torch.Tensor or None)</em> - Process bias.</p></li>
<li><p><strong>base_input_dim</strong> <em>(int)</em> - Base input dimension.</p></li>
<li><p><strong>base_output_dim</strong> <em>(int)</em> - Base output dimension.</p></li>
<li><p><strong>k</strong> <em>(int)</em> - Parameter for weight shaping.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>W_att</strong> <em>(torch.Tensor)</em> - Attention weights.</p></li>
<li><p><strong>W_fc</strong> <em>(torch.Tensor)</em> - Feature weights.</p></li>
<li><p><strong>B_att</strong> <em>(torch.Tensor)</em> - Attention biases.</p></li>
<li><p><strong>B_fc</strong> <em>(torch.Tensor)</em> - Feature biases.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">abslayer</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">base_out_dim</span><span class="p">)</span>
</pre></div>
</div>
<p>Processes an abstract layer to create a compressed layer.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>abslayer</strong> - The abstract layer to process.</p></li>
<li><p><strong>input_dim</strong> <em>(int)</em> - Input dimension of the layer.</p></li>
<li><p><strong>base_out_dim</strong> <em>(int)</em> - Base output dimension of the layer.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>CompressAbstractLayer</strong> - Instance with computed weights and biases.</p></li>
</ul>
</section>
<section id="class-compressabstractlayer-nn-module">
<h2>class CompressAbstractLayer(nn.Module)<a class="headerlink" href="#class-compressabstractlayer-nn-module" title="Link to this heading"></a></h2>
<p>A compressed abstract layer module for efficient forward computation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">att_w</span><span class="p">,</span> <span class="n">f_w</span><span class="p">,</span> <span class="n">att_b</span><span class="p">,</span> <span class="n">f_b</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>att_w</strong> <em>(torch.Tensor)</em> - Attention weights.</p></li>
<li><p><strong>f_w</strong> <em>(torch.Tensor)</em> - Feature weights.</p></li>
<li><p><strong>att_b</strong> <em>(torch.Tensor)</em> - Attention biases.</p></li>
<li><p><strong>f_b</strong> <em>(torch.Tensor)</em> - Feature biases.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Performs forward pass using attention and feature weights.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>x</strong> <em>(torch.Tensor)</em> - Input tensor of shape [batch_size, input_dim].</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Output tensor after processing, shape [batch_size, output_dim].</p></li>
</ul>
<section id="sparsemax-py-components">
<h3><strong>sparsemax.py Components</strong><a class="headerlink" href="#sparsemax-py-components" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">_make_ix_like</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Creates an index tensor with a similar shape to the input tensor.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor to match shape with.</p></li>
<li><p><strong>dim</strong> <em>(int, optional, Default is 0)</em> - Dimension to align the index tensor with.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Index tensor with shape matching the input.</p></li>
</ul>
</section>
</section>
<section id="class-sparsemaxfunction-function">
<h2>class SparsemaxFunction(Function)<a class="headerlink" href="#class-sparsemaxfunction-function" title="Link to this heading"></a></h2>
<p>Autograd function implementing the sparsemax activation (Martins &amp; Astudillo, 2016).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Forward pass to compute sparsemax activation.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>ctx</strong> - Context object to store variables for backward pass.</p></li>
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor of any shape.</p></li>
<li><p><strong>dim</strong> <em>(int, optional, Default is -1)</em> - Dimension along which to apply sparsemax.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Output tensor with the same shape as input, containing sparse probabilities.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span>
</pre></div>
</div>
<p>Backward pass to compute gradients of the loss with respect to the input.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>ctx</strong> - Context object with stored variables from forward pass.</p></li>
<li><p><strong>grad_output</strong> <em>(torch.Tensor)</em> - Gradient of the loss with respect to the output.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Gradient of the loss with respect to the input.</p></li>
<li><p><strong>None</strong> - No gradient for the <cite>dim</cite> parameter.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">_threshold_and_support</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Computes the threshold and support size for sparsemax.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor.</p></li>
<li><p><strong>dim</strong> <em>(int, optional, Default is -1)</em> - Dimension to compute over.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>tau</strong> <em>(torch.Tensor)</em> - Threshold value for sparsemax.</p></li>
<li><p><strong>support_size</strong> <em>(torch.Tensor)</em> - Number of non-zero elements (support size).</p></li>
</ul>
</section>
<section id="class-sparsemax-nn-module">
<h2>class Sparsemax(nn.Module)<a class="headerlink" href="#class-sparsemax-nn-module" title="Link to this heading"></a></h2>
<p>Module wrapping the sparsemax activation function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>dim</strong> <em>(int, optional, Default is -1)</em> - Dimension along which to apply sparsemax.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Applies sparsemax activation to the input.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Output after sparsemax activation.</p></li>
</ul>
</section>
<section id="class-entmax15function-function">
<h2>class Entmax15Function(Function)<a class="headerlink" href="#class-entmax15function-function" title="Link to this heading"></a></h2>
<p>Autograd function implementing Entmax with alpha=1.5 (Peters et al., 2019).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Forward pass to compute Entmax15 activation.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>ctx</strong> - Context object to store variables for backward pass.</p></li>
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor of any shape.</p></li>
<li><p><strong>dim</strong> <em>(int, optional, Default is -1)</em> - Dimension along which to apply Entmax15.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Output tensor with the same shape as input.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span>
</pre></div>
</div>
<p>Backward pass to compute gradients of the loss with respect to the input.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>ctx</strong> - Context object with stored variables from forward pass.</p></li>
<li><p><strong>grad_output</strong> <em>(torch.Tensor)</em> - Gradient of the loss with respect to the output.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Gradient of the loss with respect to the input.</p></li>
<li><p><strong>None</strong> - No gradient for the <cite>dim</cite> parameter.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">_threshold_and_support</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Computes the threshold and support size for Entmax15.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor.</p></li>
<li><p><strong>dim</strong> <em>(int, optional, Default is -1)</em> - Dimension to compute over.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>tau_star</strong> <em>(torch.Tensor)</em> - Threshold value for Entmax15.</p></li>
<li><p><strong>support_size</strong> <em>(torch.Tensor)</em> - Number of non-zero elements (support size).</p></li>
</ul>
</section>
<section id="class-entmoid15-function">
<h2>class Entmoid15(Function)<a class="headerlink" href="#class-entmoid15-function" title="Link to this heading"></a></h2>
<p>Optimized autograd function equivalent to Entmax15([x, 0]).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Forward pass to compute the Entmoid15 activation.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>ctx</strong> - Context object to store output for backward pass.</p></li>
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Output tensor with the same shape as input.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span>
</pre></div>
</div>
<p>Backward pass to compute gradients.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>ctx</strong> - Context object with stored output from forward pass.</p></li>
<li><p><strong>grad_output</strong> <em>(torch.Tensor)</em> - Gradient of the loss with respect to the output.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Gradient of the loss with respect to the input.</p></li>
</ul>
</section>
<section id="id1">
<h2>class Sparsemax(nn.Module)<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<p>Module wrapper for the sparsemax activation function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>dim</strong> <em>(int, optional, Default is -1)</em> - Dimension along which to apply sparsemax.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Applies sparsemax activation to the input.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Output after sparsemax activation.</p></li>
</ul>
</section>
<section id="class-entmax15-nn-module">
<h2>class Entmax15(nn.Module)<a class="headerlink" href="#class-entmax15-nn-module" title="Link to this heading"></a></h2>
<p>Module wrapper for the Entmax15 activation function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>dim</strong> <em>(int, optional, Default is -1)</em> - Dimension along which to apply Entmax15.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Applies Entmax15 activation to the input.</p>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><strong>input</strong> <em>(torch.Tensor)</em> - Input tensor.</p></li>
</ul>
<p><strong>Returns:</strong></p>
<ul class="simple">
<li><p><strong>torch.Tensor</strong> - Output after Entmax15 activation.</p></li>
</ul>
<p><strong>Referencses:</strong></p>
<p>Chen, J., Liao, K., Wan, Y., Chen, D. Z., &amp; Wu, J. (2022). DANets: Deep Abstract Networks for Tabular Data Classification and Regression. arXiv:2112.02962 [cs.LG]. <a class="reference external" href="https://arxiv.org/abs/2112.02962">https://arxiv.org/abs/2112.02962</a></p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Read the Docs core team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>