

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>num_embeddings &mdash; LAMDA-TALENT  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            LAMDA-TALENT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html">How to Use TALENT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#cloning-the-repository">1. Cloning the Repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#running-experiments">2. Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#adding-new-methods">3. Adding New Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#configuring-hyperparameters">4. Configuring Hyperparameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#troubleshooting">5. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Methods</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html">Methods in TALENT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html#deep-learning-methods">Deep Learning Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html#classical-methods">Classical Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html#methodology-summary">Methodology Summary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Dependencies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html">Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html#python-libraries">Python Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html#optional-dependencies">Optional Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dependencies.html#additional-notes">Additional Notes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmark_Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html">Benchmark Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#available-datasets">Available Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#downloading-datasets">Downloading Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#dataset-structure">Dataset Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#placing-datasets">Placing Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#using-datasets">Using Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#custom-datasets">Custom Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#task-types">Task Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_datasets.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Experimental_Results</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../experimental_results.html">Experimental Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental_results.html#evaluation-metrics">Evaluation Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental_results.html#results-summary">Results Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental_results.html#conclusion">Conclusion</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../core.html">Core Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning.html">Deep Learning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../classical_methods.html">Classical Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lib.html">Library Components</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Acknowledgements</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../acknowledgements.html">Acknowledgments</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">LAMDA-TALENT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><strong>num_embeddings</strong></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api/lib/num_embeddings.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="num-embeddings">
<h1><strong>num_embeddings</strong><a class="headerlink" href="#num-embeddings" title="Link to this heading"></a></h1>
<p>A set of functions to compute and validate bin edges for numerical feature discretization, commonly used in embeddings like piecewise linear encoding.</p>
<section id="bin-validation">
<h2><strong>Bin Validation</strong><a class="headerlink" href="#bin-validation" title="Link to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_check_bins</span><span class="p">(</span><span class="n">bins</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</pre></div>
</div>
<p>Validates the structure of bin edges to ensure they meet requirements for discretization.</p>
<p><strong>Parameters:</strong>
* <strong>bins</strong> <em>(List[Tensor])</em> - List of tensors, where each tensor contains bin edges for a feature.</p>
<p><strong>Raises:</strong>
* <strong>ValueError</strong> - If bins are empty, not 1D tensors, have fewer than 2 edges, contain non-finite values, or are unsorted.
* <strong>UserWarning</strong> - If a feature has exactly 2 bin edges (only 1 bin, equivalent to MinMax scaling).</p>
</section>
<section id="bin-edge-calculation">
<h2><strong>Bin Edge Calculation</strong><a class="headerlink" href="#bin-edge-calculation" title="Link to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_bins</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">n_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">48</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">tree_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">regression</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>
</pre></div>
</div>
<p>Computes bin edges for numerical features using either quantile-based or tree-based methods.</p>
<p><strong>Parameters:</strong>
* <strong>X</strong> <em>(torch.Tensor)</em> - 2D tensor of shape <cite>(n_samples, n_features)</cite> containing numerical features.
* <strong>n_bins</strong> <em>(int, optional, Default is 48)</em> - Target number of bins (actual count may vary).
* <strong>tree_kwargs</strong> <em>(Optional[Dict[str, Any]])</em> - If provided, uses tree-based binning with these kwargs for the decision tree.
* <strong>y</strong> <em>(Optional[Tensor])</em> - 1D tensor of labels (required for tree-based binning).
* <strong>regression</strong> <em>(Optional[bool])</em> - Whether the task is regression (required for tree-based binning).
* <strong>verbose</strong> <em>(bool, optional, Default is False)</em> - If True, uses <cite>tqdm</cite> to show progress for tree-based binning.</p>
<p><strong>Returns:</strong>
* <strong>List[Tensor]</strong> - List of tensors, where each tensor contains sorted, unique bin edges for a feature, with shape <cite>(n_edges,)</cite>.</p>
</section>
<section id="behavior-details">
<h2><strong>Behavior Details</strong><a class="headerlink" href="#behavior-details" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p><strong>Quantile-Based Binning (default, `tree_kwargs=None`)</strong>:
- Computes bin edges as quantiles of the feature distribution.
- Uses <cite>torch.quantile</cite> with <cite>n_bins + 1</cite> quantiles (from 0.0 to 1.0).
- Removes duplicate edges to ensure uniqueness.
- Validates edges with <cite>_check_bins</cite>.</p></li>
<li><p><strong>Tree-Based Binning (`tree_kwargs` provided)</strong>:
- Uses scikit-learn decision trees to find split points based on label information.
- Fits a separate tree for each feature (regression or classification, based on <cite>regression</cite>).
- Collects split thresholds from tree nodes as potential bin edges.
- Includes min/max of the feature as edge boundaries.
- Removes duplicates and sorts edges.
- Validates edges with <cite>_check_bins</cite> and returns them on the same device/dtype as <cite>X</cite>.</p></li>
</ol>
</section>
<section id="constraints-and-requirements">
<h2><strong>Constraints and Requirements</strong><a class="headerlink" href="#constraints-and-requirements" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><cite>X</cite> must be a 2D PyTorch tensor with finite values and at least 2 distinct values per feature.</p></li>
<li><p><cite>n_bins</cite> must be between 2 and <cite>len(X) - 1</cite>.</p></li>
<li><p>For tree-based binning:
- <cite>y</cite> (labels) and <cite>regression</cite> (task type) must be provided.
- <cite>tree_kwargs</cite> must not contain <cite>max_leaf_nodes</cite> (automatically set to <cite>n_bins</cite>).
- Scikit-learn must be installed (raises <cite>RuntimeError</cite> otherwise).
- <cite>tqdm</cite> is required for verbose progress (raises <cite>ImportError</cite> if missing).</p></li>
</ul>
</section>
<section id="example-use-cases">
<h2><strong>Example Use Cases</strong><a class="headerlink" href="#example-use-cases" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>Preprocessing numerical features for piecewise linear embeddings.</p></li>
<li><p>Discretizing features for tabular deep learning models.</p></li>
<li><p>Supervised binning to align splits with label patterns (tree-based method).</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">_PiecewiseLinearEncodingImpl</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</pre></div>
</div>
<p>Internal implementation of piecewise linear encoding (not recommended for direct use, as outputs contain infinite values).</p>
<section id="parameters">
<h3><strong>Parameters</strong><a class="headerlink" href="#parameters" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>bins</strong> <em>(List[Tensor])</em>: List of 1D tensors, where each tensor represents bin edges for a feature (generated by <cite>compute_bins</cite>).</p></li>
</ul>
</section>
<section id="attributes">
<h3><strong>Attributes</strong><a class="headerlink" href="#attributes" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>edges</strong> <em>(Tensor)</em>: Tensor of bin edges with shape <cite>(n_features, max_n_edges - 1)</cite>, padded with <cite>inf</cite> for uniform shape.</p></li>
<li><p><strong>width</strong> <em>(Tensor)</em>: Tensor of bin widths with the same shape as <cite>edges</cite> (computed as edge differences).</p></li>
<li><p><strong>mask</strong> <em>(Tensor)</em>: Boolean mask tensor with the same shape as <cite>edges</cite>, marking valid bins (non-padded regions).</p></li>
<li><p><strong>_bin_counts</strong> <em>(Tuple[int])</em>: Number of bins per feature (<cite>len(bins[i]) - 1</cite>).</p></li>
<li><p><strong>_same_bin_count</strong> <em>(bool)</em>: Flag indicating if all features have the same number of bins.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</pre></div>
</div>
<p>Computes piecewise linear encoding for input features.</p>
<p><strong>Parameters</strong></p>
<dl class="simple">
<dt><strong>x</strong> (<em>Tensor</em>)</dt><dd><p>Input tensor with shape <code class="docutils literal notranslate"><span class="pre">(*batch_dims,</span> <span class="pre">n_features)</span></code> (at least 2-D).</p>
</dd>
</dl>
<p><strong>Returns</strong></p>
<dl class="simple">
<dt><strong>Tensor</strong></dt><dd><p>Encoded tensor with shape <code class="docutils literal notranslate"><span class="pre">(*batch_dims,</span> <span class="pre">n_features,</span> <span class="pre">max_n_bins)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">max_n_bins</span></code> is the maximum number of bins across all features.</p>
</dd>
</dl>
</section>
</section>
<section id="class-piecewiselinearencoding-nn-module">
<h2>class PiecewiseLinearEncoding(nn.Module)<a class="headerlink" href="#class-piecewiselinearencoding-nn-module" title="Link to this heading"></a></h2>
<p>Wrapper for <code class="docutils literal notranslate"><span class="pre">_PiecewiseLinearEncodingImpl</span></code> that sanitizes outputs
(removes infinite values).</p>
<p><strong>Parameters</strong></p>
<dl class="simple">
<dt><strong>bins</strong> (<em>List[Tensor]</em>)</dt><dd><p>List of 1-D tensors, where each tensor represents the bin edges for a
feature .</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</pre></div>
</div>
<p>Computes piecewise linear encoding with cleaned outputs.</p>
<p><strong>Parameters</strong></p>
<dl class="simple">
<dt><strong>x</strong> (<em>Tensor</em>)</dt><dd><p>Input tensor with shape <code class="docutils literal notranslate"><span class="pre">(*batch_dims,</span> <span class="pre">n_features)</span></code> (at least 2-D).</p>
</dd>
</dl>
<p><strong>Returns</strong></p>
<dl>
<dt><strong>Tensor</strong></dt><dd><p>Encoded tensor:</p>
<ul>
<li><p>If all features have the same number of bins:
shape <code class="docutils literal notranslate"><span class="pre">(*batch_dims,</span> <span class="pre">n_features</span> <span class="pre">*</span> <span class="pre">n_bins)</span></code> (flattened last two dimensions).</p></li>
<li><p>If bin counts vary:
shape <code class="docutils literal notranslate"><span class="pre">(*batch_dims,</span> <span class="pre">total_valid_bins)</span></code> (filtered via mask to remove padding).</p>
<p><strong>Unary Encoding</strong></p>
</li>
</ul>
</dd>
</dl>
<hr class="docutils" />
<p>### Internal Implementation Class</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">_UnaryEncodingImpl</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</pre></div>
</div>
<p>Internal implementation of unary encoding, converting feature values into binary indicators of bin membership.</p>
<section id="id1">
<h3><strong>Parameters</strong><a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>bins</strong> <em>(List[Tensor])</em>: List of 1D tensors, where each tensor represents bin edges for a feature (generated by <cite>compute_bins</cite>).</p></li>
</ul>
<p><strong>Attributes</strong></p>
<ul class="simple">
<li><p><strong>edges</strong> <em>(Tensor)</em>: Tensor of bin edges with shape <cite>(n_features, max_n_edges - 1)</cite>, padded with <cite>inf</cite> for uniform shape.</p></li>
<li><p><strong>mask</strong> <em>(Tensor)</em>: Boolean mask tensor with the same shape as <cite>edges</cite>, marking valid bins (non-padded regions).</p></li>
<li><p><strong>_bin_counts</strong> <em>(Tuple[int])</em>: Number of bins per feature (<cite>len(bins[i]) - 1</cite>).</p></li>
<li><p><strong>_same_bin_count</strong> <em>(bool)</em>: Flag indicating if all features have the same number of bins.</p></li>
</ul>
<p><strong>Forward Method</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</pre></div>
</div>
<p>Computes unary encoding for input features.</p>
<p><strong>Parameters</strong></p>
<ul class="simple">
<li><p><strong>x</strong> <em>(Tensor)</em>: Input tensor with shape <cite>(*batch_dims, n_features)</cite> (at least 2D).</p></li>
</ul>
<p><strong>Returns</strong></p>
<ul class="simple">
<li><p><strong>Tensor</strong>: Encoded tensor with shape <cite>(*batch_dims, n_features, max_n_bins)</cite>, where <cite>max_n_bins</cite> is the maximum number of bins across all features. Values are in <cite>[0, 1]</cite>.</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Read the Docs core team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>